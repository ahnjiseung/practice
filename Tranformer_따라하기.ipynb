{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyP+IHmF8unjAttBr5sEPnGR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"RvqEN-TkUwE9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd /content/drive/MyDrive/Colab Notebooks/practice"],"metadata":{"id":"eSAcpQdZVGIr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git init\n","!git config --global user.email \"gusdudac@gmail.com\"\n","!git config --global user.name \"jiseung ahn\"\n","\n","!git status"],"metadata":{"id":"6IZyMDSvVUaA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UKsYHBjJVhy8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Tensorflow document에서 transformer 예제 따라하며 내용 파악\n","    * Input -> Positional Embedding -> Encoder -> Decoder\n","\n","    * Encoder : Multihead Self Attention -> Regidual&normalization -> FFNN\n","    \n","    * Decoder : Masked Self Attention -> Regidual&normalization -> FFNN -> Encoder/Decoder Multihead Self Attention -> Regidual&normalization -> FFNN\n"],"metadata":{"id":"IGZGDBAUlFVN"}},{"cell_type":"code","source":["# 라이브러리 설치\n","!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n","!pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text\n","!pip install protobuf~=3.20.3\n","!pip install -q tensorflow_datasets\n","!pip install -q -U tensorflow-text tensorflow"],"metadata":{"id":"e27l5aoExdm6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 라이브러리 설치\n","import logging\n","import time\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow_datasets as tfds\n","import tensorflow as tf\n","import tensorflow_text"],"metadata":{"id":"5ohU9VDRyQ-X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 예제 불러오기\n","examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en',\n","                              with_info=True,\n","                              as_supervised=True)\n","\n","train_examples, val_examples = examples['train'], examples['validation']"],"metadata":{"id":"YuSAB3yZyeni"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 영어, 포르투갈어 3개 문장 순서대로 출력\n","for pt_examples, en_examples in train_examples.batch(3).take(1):\n","    print('>Portuguese: ')\n","    for i, pt in enumerate(pt_examples.numpy()):\n","        print(\"[%i]\" % i, pt.decode('utf-8'))\n","\n","    print('>English: ')\n","    for i, en in enumerate(en_examples.numpy()):\n","        print(\"[%i]\" % i, en.decode('utf-8'))"],"metadata":{"id":"E9d8DZL4zCtR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 토크나이저 모델 불러오기\n","model_name = 'ted_hrlr_translate_pt_en_converter'\n","tf.keras.utils.get_file(\n","    f'{model_name}.zip',\n","    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n","    cache_dir='.', cache_subdir='', extract=True\n",")"],"metadata":{"id":"1hOAe7MC06cf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 토크나이저 생성\n","tokenizers = tf.saved_model.load(model_name)"],"metadata":{"id":"sbMuv6xs1kGF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 토크나이즈 결과 확인\n","# 각 단어를 token index로 변환\n","encoded = tokenizers.en.tokenize(en_examples)\n","encoded"],"metadata":{"id":"WHub491g1uZU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# raw데이터-encode 데이터 decode 변환 결과 비교\n","en_examples, \\\n","tokenizers.en.detokenize(encoded)"],"metadata":{"id":"NWvuZhzJ2Kia"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 예시 데이터의 문장 길이 확인\n","length=[]\n","for pt_examples, en_examples in train_examples.batch(1024):\n","    pt_tokens = tokenizers.pt.tokenize(pt_examples)\n","    length.append(pt_tokens.row_lengths())\n","\n","    en_tokens = tokenizers.en.tokenize(en_examples)\n","    length.append(en_tokens.row_lengths())\n","    print('.', end='', flush=True)"],"metadata":{"id":"KyjpgbJy2PAt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_lengths = np.concatenate(length)\n","\n","plt.hist(all_lengths, np.linspace(0, 500, 101))\n","plt.ylim(plt.ylim())\n","max_length = max(all_lengths)\n","plt.plot([max_length, max_length], plt.ylim())\n","plt.title(f'Maximum tokens per example: {max_length}');"],"metadata":{"id":"n31RFcNH3mhZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# token길이 최대 128까지 자르기\n","MAX_TOKENS=128 # sequence length : 128\n","def prepare_batch(pt, en):\n","    pt = tokenizers.pt.tokenize(pt)      # Output is ragged.\n","    pt = pt[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n","    pt = pt.to_tensor()  # Convert to 0-padded dense Tensor\n","\n","    en = tokenizers.en.tokenize(en)\n","    en = en[:, :(MAX_TOKENS+1)]\n","    en_inputs = en[:, :-1].to_tensor()  # Drop the [END] tokens\n","    en_labels = en[:, 1:].to_tensor()   # Drop the [START] tokens\n","\n","    return (pt, en_inputs), en_labels"],"metadata":{"id":"YFhXbrJD4FyT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BUFFER_SIZE = 20000\n","BATCH_SIZE = 64"],"metadata":{"id":"NI37pr94HErj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_batches(ds):\n","  return (\n","      ds\n","      .shuffle(BUFFER_SIZE)\n","      .batch(BATCH_SIZE)\n","      .map(prepare_batch, tf.data.AUTOTUNE)\n","      .prefetch(buffer_size=tf.data.AUTOTUNE))"],"metadata":{"id":"fZftpMP2HEig"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create training and validation set batches.\n","train_batches = make_batches(train_examples)\n","val_batches = make_batches(val_examples)"],"metadata":{"id":"l5rGdx-S68ib"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# positional Embedding\n","def positional_encoding(length, depth):\n","    depth = depth/2\n","\n","    positions = np.arange(length)[:,np.newaxis]     # (seq, 1)\n","    depths = np.arange(depth)[np.newaxis, :]/depth  # (1, depth)\n","\n","    angle_rates = 1/(10000**depths)\n","    angle_rads = positions * angle_rates\n","\n","    pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)], axis=1)\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)"],"metadata":{"id":"nBO5x90k8_zJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 변수 positions - 현재 시퀀스 순서\n","    * array([[0],\n","       [1],\n","       [2],\n","       [3]])\n","\n","* 변수 depths : 현재 시퀀스 순서에 따른 가중치로 이해, 순서가 뒤로 갈수록 값이 커지며 token의 공간상 거리 의미 추가\n","    * ex) array([[0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]])\n","\n","* Embedding : 자연어처리에서 사람이 쓰는 자연어를 기계가 이해할 수 있도록 숫자형태인 vector로 바꾸는 과정 혹은 일련의 전체 과정\n","    * Input의 shape 변경, 차원의 확장\n","    * ex) (3,4) -> (3, 4, 512)"],"metadata":{"id":"xdOa5rKVEIS2"}},{"cell_type":"code","source":["# input data의 공간상 거리적 의미 부여\n","class PositionalEmbedding(tf.keras.layers.Layer):\n","    def __init__(self, vocab_size, d_model):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n","        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n","\n","    def compute_mask(self, *args, **kwargs):\n","        return self.embedding.compute_mask(*args, **kwargs)\n","\n","    # call함수는 생성된 클래스의 input에 대한 연산 수행\n","    def call(self, x):\n","        length = tf.shape(x)[1] # input sequence length\n","        x = self.embedding(x)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32)) # scaling positional encoding\n","        x = x + self.pos_encoding[tf.newaxis, :length, :] # input + positional embedding, shape 변환\n","        return x"],"metadata":{"id":"flQ8zcMfBSih"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# self-attention base process\n","# Multihead Attention - Regidual connection(positional embedding 정보 + mha output) - normalization\n","class BaseAttention(tf.keras.layers.Layer):\n","    def __init__(self, **kwargs):\n","        super().__init__()\n","        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n","        self.layernorm = tf.keras.layers.LayerNormalization()\n","        self.add = tf.keras.layers.Add()"],"metadata":{"id":"Y-XFon_jRj46"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Part of Encoder-Decoder Self Attention\n","# context : Encoder output\n","class CrossAttention(BaseAttention):\n","    def call(self, x, context):\n","        attn_output, attn_scores = self.mha(\n","            query = x,\n","            key=context, # Encoder output -> Decoder input으로\n","            value=context, # Encoder output -> Decoder input으로\n","            return_attention_scores=True\n","        )\n","\n","        self.last_attn_scores = attn_scores # dot_product(Query,Key.T)\n","\n","        x = self.add([x, attn_output]) # Regidual connection\n","        x = self.layernorm(x) # normalization\n","\n","        return x"],"metadata":{"id":"CQCsPIF-iRaH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Part of Encoder Self Attention\n","class GlobalSelfAttention(BaseAttention):\n","    def call(self, x):\n","        attn_output = self.mha(\n","            query=x,\n","            value=x,\n","            key=x)\n","        x = self.add([x, attn_output])\n","        x = self.layernorm(x)\n","        return x"],"metadata":{"id":"CL9sL0vPiUeu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Part of Decoder Masked Self Attention\n","# input : 예측하고자 하는 대상\n","class CausalSelfAttention(BaseAttention):\n","    def call(self, x):\n","        attn_output = self.mha(\n","            query =x,\n","            value=x,\n","            key=x,\n","            use_causal_mask=True) # masked self-attention\n","        x= self.add([x, attn_output])\n","        x= self.layernorm(x)\n","        return x"],"metadata":{"id":"rj5CMJHBoIpe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FFNN layer\n","class FeedForward(tf.keras.layers.Layer):\n","    def __init__(self, d_model, dff, dropout_rate = 0.1):\n","        super().__init__()\n","        self.seq = tf.keras.Sequential([\n","            tf.keras.layers.Dense(dff, activation='relu'),\n","            tf.keras.layers.Dense(d_model),\n","            tf.keras.layers.Dropout(dropout_rate)\n","        ])\n","        self.add = tf.keras.layers.Add()\n","        self.layernorm = tf.keras.layers.LayerNormalization()\n","\n","    def call(self, x):\n","        x = self.add([x, self.seq(x)])\n","        x = self.layernorm(x)\n","        return x"],"metadata":{"id":"cYrEIRW8rItG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make Encoder Layer\n","# GlobalSelfAttention - FFNN\n","class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, *, d_model, num_heads,\n","                 dff, dropout_rate=0.1):\n","        super().__init__()\n","\n","        self.self_attention = GlobalSelfAttention(\n","            num_heads=num_heads,\n","            key_dim = d_model,\n","            dropout = dropout_rate\n","        )\n","\n","        self.ffn = FeedForward(d_model, dff)\n","\n","    def call(self, x):\n","        x = self.self_attention(x)\n","        x = self.ffn(x)\n","        return x"],"metadata":{"id":"QTvE7ykduIZx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, *, num_layers, d_model, num_heads,\n","                 dff, vocab_size, dropout_rate=0.1):\n","        super().__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.pos_embedding = PositionalEmbedding(\n","            vocab_size = vocab_size, d_model=d_model)\n","\n","        self.enc_layers = [\n","            EncoderLayer(d_model=d_model,\n","                         num_heads = num_heads,\n","                         dff=dff,\n","                         dropout_rate=dropout_rate)\n","            for _ in range(num_layers)]\n","\n","        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","\n","    def call(self, x):\n","        x = self.pos_embedding(x)\n","\n","        x = self.dropout(x)\n","\n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x)\n","\n","        return x"],"metadata":{"id":"TBLgftbQJ8Uz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, *, d_model, num_heads,\n","                 dff, dropout_rate=0.1):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.causal_self_attention = CausalSelfAttention(\n","            num_heads = num_heads,\n","            key_dim=d_model,\n","            dropout = dropout_rate\n","        )\n","\n","        self.cross_attention = CrossAttention(\n","            num_heads=num_heads,\n","            key_dim = d_model,\n","            dropout = dropout_rate\n","        )\n","\n","        self.fnn = FeedForward(d_model, dff)\n","\n","    def call(self, x, context):\n","        x = self.causal_self_attention(x=x)\n","        x = self.cross_attention(x=x, context = context)\n","\n","        self.last_attn_scores = self.cross_attention.last_attn_scores\n","\n","        x = self.fnn(x)\n","\n","        return x"],"metadata":{"id":"lz6xtPm_UH4c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Decoder(tf.keras.layers.Layer):\n","    def __init__(self, *, num_layers, d_model, num_heads,\n","                 dff, vocab_size, dropout_rate = 0.1):\n","        super(Decoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n","                                                 d_model=d_model)\n","        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","        self.dec_layers = [DecoderLayer(\n","            d_model = d_model,\n","            num_heads = num_heads,\n","            dff=dff,\n","            dropout_rate = dropout_rate\n","        )\n","        for _ in range(num_layers)]\n","\n","        self.last_attn_scores = None\n","\n","    def call(self, x, context):\n","        x = self.pos_embedding(x)\n","        x = self.dropout(x)\n","\n","        for i in range(self.num_layers):\n","            x = self.dec_layers[i](x, context)\n","\n","        self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n","\n","        return x"],"metadata":{"id":"RQytmV-cXXFv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Transformer(tf.keras.Model):\n","    def __init__(self, *, num_layers, d_model, num_heads, dff,\n","                 input_vocab_size, target_vocab_size, dropout_rate=0.1):\n","        super().__init__()\n","\n","        self.encoder = Encoder(\n","            num_layers=num_layers,\n","            d_model = d_model,\n","            num_heads=num_heads,\n","            dff=dff,\n","            vocab_size=input_vocab_size,\n","            dropout_rate=dropout_rate\n","        )\n","\n","        self.decoder = Decoder(\n","            num_layers=num_layers,\n","            d_model = d_model,\n","            num_heads=num_heads,\n","            dff=dff,\n","            vocab_size=target_vocab_size,\n","            dropout_rate=dropout_rate\n","        )\n","\n","        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","\n","    def call(self, inputs):\n","        context, x = inputs\n","\n","        context = self.encoder(context)\n","\n","        x = self.decoder(x, context)\n","\n","        logits = self.final_layer(x)\n","\n","        try:\n","        # Drop the keras mask, so it doesn't scale the losses/metrics.\n","        # b/250038731\n","            del logits._keras_mask\n","        except AttributeError:\n","            pass\n","\n","            # Return the final output and the attention weights.\n","        return logits"],"metadata":{"id":"deqGIaegbEiY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_layers = 4\n","d_model = 128\n","dff = 512\n","num_heads = 8\n","dropout_rate = 0.1"],"metadata":{"id":"Er-cU4iSfcAz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformer = Transformer(\n","    num_layers=num_layers,\n","    d_model=d_model,\n","    num_heads=num_heads,\n","    dff=dff,\n","    input_vocab_size=tokenizers.pt.get_vocab_size().numpy(),\n","    target_vocab_size=tokenizers.en.get_vocab_size().numpy(),\n","    dropout_rate=dropout_rate)"],"metadata":{"id":"dhV_jTF6fgFU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output = transformer((pt, en))\n","\n","print(en.shape)\n","print(pt.shape)\n","print(output.shape)"],"metadata":{"id":"uFid1kj2fif0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["attn_scores = transformer.decoder.dec_layers[-1].last_attn_scores\n","print(attn_scores.shape)  # (batch, heads, target_seq, input_seq)"],"metadata":{"id":"ocRzIKMBgdNr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformer.summary()"],"metadata":{"id":"4L8HYOBvhT7m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Customize learning_rate\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super().__init__()\n","\n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","    self.warmup_steps = warmup_steps\n","\n","  def __call__(self, step):\n","    step = tf.cast(step, dtype=tf.float32)\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps ** -1.5)\n","\n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"],"metadata":{"id":"BGBpVowwh8AV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["learning_rate = CustomSchedule(d_model)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n","                                     epsilon=1e-9)"],"metadata":{"id":"5wO4nKhOiEKS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n","plt.ylabel('Learning Rate')\n","plt.xlabel('Train Step')"],"metadata":{"id":"SBPQR8DkiEuf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def masked_loss(label, pred):\n","  mask = label != 0\n","  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","  loss = loss_object(label, pred)\n","\n","  mask = tf.cast(mask, dtype=loss.dtype)\n","  loss *= mask\n","\n","  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n","  return loss\n","\n","\n","def masked_accuracy(label, pred):\n","  pred = tf.argmax(pred, axis=2)\n","  label = tf.cast(label, pred.dtype)\n","  match = label == pred\n","\n","  mask = label != 0\n","\n","  match = match & mask\n","\n","  match = tf.cast(match, dtype=tf.float32)\n","  mask = tf.cast(mask, dtype=tf.float32)\n","  return tf.reduce_sum(match)/tf.reduce_sum(mask)"],"metadata":{"id":"BJxMK7QIiHiH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformer.compile(\n","    loss=masked_loss,\n","    optimizer=optimizer,\n","    metrics=[masked_accuracy])"],"metadata":{"id":"B3vXnLKxid4U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformer.fit(train_batches,\n","                epochs=20,\n","                validation_data=val_batches)"],"metadata":{"id":"EaO173jMisOI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MkBh9X0riuRq"},"execution_count":null,"outputs":[]}]}